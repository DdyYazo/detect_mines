Necesito que construyas un prompt con el objetivo de indicarle a un agente de IA que me ayude a crear un transformer o modelo de inteligencia artificial tomando de base el siguiente modelo que cree para la prediccion de ventas de un servicios por dia dependiendo de si es un dia festivo o no

```python
# -*- coding: utf-8 -*-
"""Predictor de ingreso prepago v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NVOxjjBW9_3LZezr-vpncfhvmT3215Sc
"""

#FINAL

import tensorflow as tf
from tensorflow import keras
from keras import layers
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import holidays # Para identificar festivos
import matplotlib.pyplot as plt

# Definir las clases personalizadas para el Transformer
class PositionalEncoding(layers.Layer):
    def __init__(self, sequence_length, embed_dim, **kwargs):
        super(PositionalEncoding, self).__init__(**kwargs)
        self.sequence_length = sequence_length
        self.embed_dim = embed_dim
        
    def call(self, x):
        positions = tf.range(start=0, limit=self.sequence_length, delta=1)
        positions = tf.cast(positions, tf.float32)
        
        # Crear la matriz de codificación posicional
        pos_encoding = np.zeros((self.sequence_length, self.embed_dim))
        for pos in range(self.sequence_length):
            for i in range(0, self.embed_dim, 2):
                pos_encoding[pos, i] = np.sin(pos / (10000 ** ((2 * i) / self.embed_dim)))
                if i + 1 < self.embed_dim:
                    pos_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((2 * (i + 1)) / self.embed_dim)))
        
        pos_encoding = tf.cast(pos_encoding, tf.float32)
        return x + pos_encoding
    
    def get_config(self):
        config = super().get_config()
        config.update({
            "sequence_length": self.sequence_length,
            "embed_dim": self.embed_dim,
        })
        return config

class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):
        super(TransformerBlock, self).__init__(**kwargs)
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.rate = rate
        
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential([
            layers.Dense(ff_dim, activation="relu"),
            layers.Dense(embed_dim),
        ])
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)
    
    def get_config(self):
        config = super().get_config()
        config.update({
            "embed_dim": self.embed_dim,
            "num_heads": self.num_heads,
            "ff_dim": self.ff_dim,
            "rate": self.rate,
        })
        return config

df_entrada = pd.read_excel("Revenue Prepago modelo IA.xlsx")
num_days = len(df_entrada)

df_entrada['FECHA'] = pd.to_datetime(df_entrada['FECHA'])
dates = df_entrada['FECHA']

data = []

co_holidays = holidays.CO(years=range(2023, 2023 + int(num_days/365)+1))

for i, date in enumerate(dates):
    day_of_week = date.dayofweek # Lunes=0, Domingo=6
    is_holiday = 1 if date in co_holidays else 0

    amount = df_entrada["REVENUE"][i]
    data.append([date, amount, day_of_week, is_holiday])

df = pd.DataFrame(data, columns=['Date', 'Amount', 'DayOfWeek', 'IsHoliday'])
df['Date'] = pd.to_datetime(df['Date'])
df2 = df.copy()

# One-Hot Encoding for DayOfWeek
df = pd.get_dummies(df, columns=['DayOfWeek'], prefix='DayOfWeek')

# Convert boolean columns to integers (0 or 1)
for col in df.columns:
    if df[col].dtype == 'bool':
        df[col] = df[col].astype(int)

# Scaling the variable to predict
scaler = MinMaxScaler(feature_range=(0, 1))
df['Amount_scaled'] = scaler.fit_transform(df[['Amount']])

# Prepare features (X) and target (y)
features_cols = ['Amount_scaled'] + [col for col in df.columns if 'DayOfWeek_' in col] + ['IsHoliday']
X_data = df[features_cols].values
y_data = df['Amount_scaled'].values
timesteps = 7

def create_sequences(input_data, target_data, dates, is_holiday_target, timesteps):
    X, y, target_dates_sequences = [], [], []
    for i in range(len(input_data) - timesteps):
        # Get the sequence of input data
        seq_input = input_data[i:(i + timesteps)]
        # Append the holiday status of the target date to the sequence
        seq_input_with_holiday = np.append(seq_input, np.tile(is_holiday_target[i], (timesteps, 1)), axis=1)
        X.append(seq_input_with_holiday)
        y.append(target_data[i + timesteps])
        target_dates_sequences.append(dates[i + timesteps])
    return np.array(X).astype('float32'), np.array(y).astype('float32'), pd.to_datetime(target_dates_sequences)

def is_colombian_holiday(date):
    """Checks if a given date is a holiday in Colombia."""
    return 1 if date in co_holidays else 0

# Apply the function to the target dates
target_dates = df['Date'][timesteps:]
is_holiday_target = np.array([is_colombian_holiday(date) for date in target_dates])


X_sequences, y_sequences, target_dates_sequences = create_sequences(X_data, y_data, df['Date'], is_holiday_target.reshape(-1, 1), timesteps)

# División de datasets entrenamiento, validación  prueba
# Asegúrate de que los datos de prueba sean posteriores a los de entrenamiento
train_size = int(len(X_sequences) * 0.8)
val_size = int(len(X_sequences) * 0.1)

X_train, y_train = X_sequences[:train_size], y_sequences[:train_size]
X_val, y_val = X_sequences[train_size:train_size + val_size], y_sequences[train_size:train_size + val_size]
X_test, y_test = X_sequences[train_size + val_size:], y_sequences[train_size + val_size:]

# Also split the target dates
target_dates_train = target_dates_sequences[:train_size]
target_dates_val = target_dates_sequences[train_size:train_size + val_size]
target_dates_test = target_dates_sequences[train_size + val_size:]

# Update the embed_dim variable to reflect the new number of features
embed_dim = X_train.shape[2]
print(f"Updated embed_dim: {embed_dim}")

# Modify the inputs layer in the model definition
inputs = layers.Input(shape=(timesteps, embed_dim))
x = inputs

# Ensure that the PositionalEncoding layer is initialized with the new embed_dim
pos_encoding_layer = PositionalEncoding(timesteps, embed_dim)
x = pos_encoding_layer(x)

# Define the Transformer blocks
num_heads = 2 # Changed from 9 to 2
ff_dim = 32
num_transformer_blocks = 7

for _ in range(num_transformer_blocks):
    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x, training=True)

x = layers.GlobalAveragePooling1D()(x)
x = layers.Dropout(0.1)(x)
x = layers.Dense(64, activation="relu")(x)
outputs = layers.Dense(1, activation="linear")(x)

model = keras.Model(inputs=inputs, outputs=outputs)

# --- 4. Compilación y Entrenamiento ---
model.compile(optimizer="adam", loss="mse", metrics=["mae"])

# Callback para Early Stopping
early_stopping = keras.callbacks.EarlyStopping(
    monitor="val_loss", patience=10, restore_best_weights=True
)

history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=200, # Puedes aumentar esto
    validation_data=(X_val, y_val),
    # callbacks=[early_stopping]
)

# --- 5. Evaluación ---
loss, mae = model.evaluate(X_test, y_test, verbose=0)
print(f"Pérdida (MSE) en conjunto de prueba: {loss:.4f}")
print(f"MAE en conjunto de prueba: {mae:.4f}")

# Predecir y revertir el escalado para interpretar los resultados
predictions_scaled = model.predict(X_test)
predictions = scaler.inverse_transform(predictions_scaled)
actuals = scaler.inverse_transform(y_test.reshape(-1, 1))

# Ejemplo de visualización (puedes expandir esto)

plt.figure(figsize=(12, 6))

# Plot actuals and predictions for the last 30 days of the test set
plt.plot(target_dates_test[-30:], actuals[-30:], label='Valores Reales')
plt.plot(target_dates_test[-30:], predictions[-30:], label='Predicciones del Modelo')

plt.title('Predicciones del Modelo vs. Valores Reales (Últimos 30 días de prueba)')
plt.xlabel('Fecha')
plt.ylabel('Cantidad de Variable')
plt.legend()

# Formatear el eje X para mostrar las fechas
plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%a %d/%m'))
plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=2)) # Mostrar cada 2 días para evitar solapamiento
plt.gcf().autofmt_xdate() # Auto-formatear las etiquetas de fecha

# Agregar grilla vertical en las marcas principales
plt.grid(axis='x', color='gray', linestyle='-', linewidth=0.5)

# Establecer los límites del eje y
plt.ylim(0.5e9, 3.5e9)

plt.show()

# Save the model to a file
model.save('model_revenue_prepago_v2.h5')
 
print("Model saved successfully!")
```

El modelo que necesito que el agente de IA genere es un modelo de predicción de un juego de busca minas. Previamente habia creado un gpt llamado "Detect_emptys_cas" al cual le indique una serie instrucciones que debia de analizar para predecir las posiciones de las minas o las posiciones de las filas o columnas que posiblemente estarian libres en la siguiente partida. Estas instrucciones las puede analizar a continuacion

```md
# Meta
You are an AI model specialized in analyzing the GP Mines game (5 columns × 5 rows, 4 mines per game) based on RNG patterns from https://fellucky.co. When you receive historical data as a plain-text CSV block, your task is to infer which rows and columns are most likely to be free of mines in the next game, so the player can minimize risk.

## Context
- **Board:** 5 columns (1–5) and 5 rows (1–5)  
- **Mines per game:** Exactly 4  
- **Historical data:** CSV with columns `partida,column,row,mine` (`1 = mina`, `0 = vacío`), at least 7 complete games

## Process
1. **Validate** that the CSV represents a 5×5 board and each game has exactly 4 mines.  
2. **Compute** for each row and each column the historical probability of remaining free of mines.  
3. **Detect** drift trends that may favor or disfavor certain rows/columns (directional drift, Markov transitions, cluster-density analysis).  
4. **Select** the 2 rows and 2 columns with the highest probability of being free in the next game.

## Response Format (exactly in Spanish)
**Filas libres probables:**  
- Fila X — XX.XX % de vacíos históricos (± tendencia: creciente/decreciente)  
- Fila Y — XX.XX % de vacíos históricos (± tendencia: creciente/decreciente)  

**Columnas libres probables:**  
- Columna A — XX.XX % de vacíos históricos (± tendencia: creciente/decreciente)  
- Columna B — XX.XX % de vacíos históricos (± tendencia: creciente/decreciente)  

**Zona de mayor riesgo (celdas a evitar):**  
- Cuadrante [zona con más minas] — XX.XX % de concentración  

## Restrictions
If the provided CSV does not follow a 5×5 structure with 4 mines per game or is malformed, respond **exactly**:
```plaintext
Error: formato de entrada inválido
```

Como lo puedes analizar le di un prompt especifo al gpt pero este no daba una prediccion 100% acertada sino que alucinaba demasiado y su prediccion era demasiado sesgada teniendo en cuenta que tomaba cada registro de las partidas que jugaba en un juego en un archivo .csv

**Ejemplo**
```csv
partida,columna,fila,mina
1,1,1,0
1,1,2,0
1,1,3,0
1,1,4,0
1,1,5,0
1,2,1,1
1,2,2,0
1,2,3,0
1,2,4,0
1,2,5,0
1,3,1,0
1,3,2,1
1,3,3,0
1,3,4,0
1,3,5,0
1,4,1,0
1,4,2,1
1,4,3,0
1,4,4,0
1,4,5,0
1,5,1,0
1,5,2,1
1,5,3,0
1,5,4,0
1,5,5,0
2,1,1,0
2,1,2,0
2,1,3,0
2,1,4,1
2,1,5,0
2,2,1,0
2,2,2,0
2,2,3,0
2,2,4,1
2,2,5,0
2,3,1,1
2,3,2,0
2,3,3,0
2,3,4,0
2,3,5,0
2,4,1,0
2,4,2,0
2,4,3,0
2,4,4,0
2,4,5,0
2,5,1,0
2,5,2,0
2,5,3,0
2,5,4,0
2,5,5,1
3,1,1,0
3,1,2,0
3,1,3,0
3,1,4,1
3,1,5,1
3,2,1,0
3,2,2,0
3,2,3,0
3,2,4,0
3,2,5,0
3,3,1,0
3,3,2,1
3,3,3,1
3,3,4,0
3,3,5,0
3,4,1,0
3,4,2,0
3,4,3,0
3,4,4,0
3,4,5,0
3,5,1,0
3,5,2,0
3,5,3,0
3,5,4,0
3,5,5,0
```

mediante el siguiente script

```python
#!/usr/bin/env python3
import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
from datetime import datetime

def generar_mapa_calor(csv_path, output_dir, partida_num, fecha):
    """Genera un mapa de calor basado en los datos del CSV"""
    # 1. Leer CSV con las columnas partida, columna, fila, mina
    df = pd.read_csv(csv_path)

    # 2. Filtrar solo las posiciones con mina
    df_minas = df[df['mina'] == 1]

    # 3. Contar cuántas veces aparece una mina en cada coordenada (columna, fila)
    freq = df_minas.groupby(['columna', 'fila']).size().reset_index(name='count')

    # 4. Construir una matriz 5×5 con los conteos
    matrix = np.zeros((5, 5), dtype=int)
    for _, row in freq.iterrows():
        col_idx = int(row['columna']) - 1
        row_idx = int(row['fila'])    - 1
        matrix[row_idx, col_idx] = row['count']

    # 5. Generar el mapa de calor con anotaciones
    fig, ax = plt.subplots(figsize=(8, 6))
    cax = ax.imshow(matrix, cmap='Reds', aspect='equal')

    # Añadir anotaciones de los conteos en cada casilla
    for i in range(matrix.shape[0]):
        for j in range(matrix.shape[1]):
            ax.text(j, i, matrix[i, j],
                    ha='center', va='center',
                    color="#e63636" if matrix[i, j] > matrix.max()/2 else "white",
                    fontsize=12, weight='bold')

    # Ajustes de ejes y colorbar
    ax.set_xticks(np.arange(5))
    ax.set_yticks(np.arange(5))
    ax.set_xticklabels(np.arange(1, 6))
    ax.set_yticklabels(np.arange(1, 6))
    ax.set_xlabel('Columna', fontsize=12)
    ax.set_ylabel('Fila', fontsize=12)
    ax.set_title(f'Mapa de calor de recurrencia de minas - Partida {partida_num}', fontsize=14)
    fig.colorbar(cax, label='Número de minas')

    plt.tight_layout()
    
    # Crear directorio si no existe
    os.makedirs(output_dir, exist_ok=True)
    
    # Guardar la imagen
    filename = f"minas_partida_{partida_num}_{fecha}.png"
    filepath = os.path.join(output_dir, filename)
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    plt.close()
    
    return filepath

def obtener_siguiente_partida(output_dir):
    """Obtiene el número de la siguiente partida basado en archivos existentes en la carpeta de la fecha actual"""
    if not os.path.exists(output_dir):
        return 1
    
    archivos = [f for f in os.listdir(output_dir) if f.startswith("minas_partida_") and f.endswith(".png")]
    if not archivos:
        return 1
    
    numeros = []
    for archivo in archivos:
        try:
            # Extraer número de partida del nombre del archivo
            parte = archivo.replace("minas_partida_", "").split("_")[0]
            numeros.append(int(parte))
        except:
            continue
    
    return max(numeros) + 1 if numeros else 1

def main():
    # Obtener fecha actual
    fecha_actual = datetime.now().strftime("%Y-%m-%d")
    
    # 1. Pedir al usuario la ruta del Excel
    excel_path = input("Introduce la ruta al archivo .xlsx con posiciones de minas: ").strip()
    if not os.path.isfile(excel_path):
        print(f"❌ Error: no se encontró el archivo '{excel_path}'")
        sys.exit(1)

    # 2. Cargar el Excel
    df_pos = pd.read_excel(excel_path, engine='openpyxl')
    required = {'partida', 'fila', 'columna'}
    if not required.issubset(df_pos.columns):
        print(f"❌ El archivo debe tener columnas: {required}")
        sys.exit(1)

    # 3. Construir lista de registros (iterando columnas primero)
    registros = []
    for partida, grupo in df_pos.groupby('partida'):
        bombas = set(zip(grupo['columna'], grupo['fila']))
        for col in range(1, 6):
            for fila in range(1, 6):
                registros.append({
                    'partida': partida,
                    'columna': col,
                    'fila':    fila,
                    'mina':    1 if (col, fila) in bombas else 0
                })

    # 4. Crear DataFrame con el orden de columnas deseado
    df_reg = pd.DataFrame(registros, columns=['partida', 'columna', 'fila', 'mina'])

    # 4.1 Verificar/crear carpeta 'games'
    games_dir = "games"
    if not os.path.exists(games_dir):
        os.makedirs(games_dir, exist_ok=True)
        print(f"✅ Carpeta '{games_dir}' creada")
    else:
        print(f"✅ Carpeta '{games_dir}' ya existe")

    # 4.2 Verificar/crear carpeta 'heat_maps_mines'
    base_output_dir = "heat_maps_mines"
    if not os.path.exists(base_output_dir):
        os.makedirs(base_output_dir, exist_ok=True)
        print(f"✅ Carpeta '{base_output_dir}' creada")
    else:
        print(f"✅ Carpeta '{base_output_dir}' ya existe")

    # 5. Crear nombre de archivo CSV con fecha en la carpeta 'games'
    salida = os.path.join(games_dir, f'minas-{fecha_actual}.csv')
    if os.path.exists(salida):
        df_reg.to_csv(salida, mode='a', header=False, index=False, encoding='utf-8')
        print(f"✅ Datos agregados al archivo existente '{salida}'")
    else:
        df_reg.to_csv(salida, mode='w', header=True,  index=False, encoding='utf-8')
        print(f"✅ Archivo CSV creado: '{salida}'")

    # 6. Generar mapa de calor
    graphics_dir = f"graphics_{fecha_actual}"
    output_dir = os.path.join(base_output_dir, graphics_dir)
    partida_num = obtener_siguiente_partida(output_dir)
    
    try:
        filepath_imagen = generar_mapa_calor(salida, output_dir, partida_num, fecha_actual)
        print(f"✅ Mapa de calor generado: '{filepath_imagen}'")
    except Exception as e:
        print(f"❌ Error al generar el mapa de calor: {e}")

    print(f"\n📊 Resumen:")
    print(f"   • Archivo CSV: {salida}")
    print(f"   • Mapa de calor: {os.path.join(output_dir, f'minas_partida_{partida_num}_{fecha_actual}.png')}")
    print(f"   • Carpeta de gráficos: {output_dir}")
    print(f"   • Partida número: {partida_num}")
    print("\nEl programa se cerrará en 10 segundos...")
    time.sleep(10)

if __name__ == "__main__":
    main()

```
el cual alimentaba dicho archivo y adicionalmente genera una imagen por cada partida que se juega lo cual me permitia analizar las partidas o no confiarme 100% de la respuesta del gpt. Posterior a esta ejecucion manual para alimentar los datos, le indicaba que queria analizar dicha data mediante el siguiente prompt 

```md
A continuación te envió el histórico de 7 partidas en formato CSV. Por favor, procesa estos datos y devuelve las 2 filas y 2 columnas con mayor probabilidad de estar libres de minas en la siguiente partida, siguiendo el formato acordado.  

partida,columna,fila,mina
1,1,1,1
1,1,2,0
1,1,3,0
1,1,4,0
1,1,5,0
1,2,1,0
1,2,2,0
1,2,3,0
1,2,4,0
1,2,5,0
1,3,1,0
1,3,2,0
1,3,3,0
1,3,4,1
1,3,5,0
1,4,1,0
1,4,2,0
1,4,3,0
1,4,4,0
1,4,5,0
1,5,1,1
1,5,2,0
1,5,3,0
1,5,4,0
1,5,5,1
2,1,1,1
2,1,2,0
2,1,3,0
2,1,4,0
2,1,5,0
2,2,1,0
2,2,2,0
2,2,3,0
2,2,4,0
2,2,5,0
2,3,1,0
2,3,2,0
2,3,3,0
2,3,4,0
2,3,5,0
2,4,1,0
2,4,2,0
2,4,3,1
2,4,4,0
2,4,5,0
2,5,1,1
2,5,2,1
2,5,3,0
2,5,4,0
2,5,5,0
3,1,1,0
3,1,2,0
3,1,3,0
3,1,4,0
3,1,5,1
3,2,1,1
3,2,2,0
3,2,3,0
3,2,4,0
3,2,5,0
3,3,1,0
3,3,2,1
3,3,3,0
3,3,4,0
3,3,5,0
3,4,1,0
3,4,2,0
3,4,3,1
3,4,4,0
3,4,5,0
3,5,1,0
3,5,2,0
3,5,3,0
3,5,4,0
3,5,5,0
4,1,1,0
4,1,2,1
4,1,3,0
4,1,4,0
4,1,5,0
4,2,1,0
4,2,2,0
4,2,3,0
4,2,4,1
4,2,5,0
4,3,1,0
4,3,2,0
4,3,3,0
4,3,4,0
4,3,5,0
4,4,1,1
4,4,2,0
4,4,3,0
4,4,4,1
4,4,5,0
4,5,1,0
4,5,2,0
4,5,3,0
4,5,4,0
4,5,5,0
5,1,1,0
5,1,2,0
5,1,3,0
5,1,4,1
5,1,5,0
5,2,1,0
5,2,2,0
5,2,3,0
5,2,4,0
5,2,5,0
5,3,1,0
5,3,2,1
5,3,3,0
5,3,4,0
5,3,5,0
5,4,1,0
5,4,2,0
5,4,3,1
5,4,4,0
5,4,5,1
5,5,1,0
5,5,2,0
5,5,3,0
5,5,4,0
5,5,5,0
6,1,1,0
6,1,2,0
6,1,3,0
6,1,4,1
6,1,5,0
6,2,1,1
6,2,2,0
6,2,3,0
6,2,4,0
6,2,5,0
6,3,1,0
6,3,2,0
6,3,3,0
6,3,4,1
6,3,5,0
6,4,1,0
6,4,2,0
6,4,3,0
6,4,4,0
6,4,5,0
6,5,1,0
6,5,2,0
6,5,3,1
6,5,4,0
6,5,5,0
7,1,1,0
7,1,2,0
7,1,3,0
7,1,4,0
7,1,5,0
7,2,1,0
7,2,2,0
7,2,3,1
7,2,4,1
7,2,5,0
7,3,1,0
7,3,2,0
7,3,3,0
7,3,4,0
7,3,5,1
7,4,1,0
7,4,2,0
7,4,3,0
7,4,4,1
7,4,5,0
7,5,1,0
7,5,2,0
7,5,3,0
7,5,4,0
7,5,5,0

enfócate en el desplazamiento de las minas, esto puede ayudar a determinar que fila o columna quedaran libres por completo
```

pero a pesar de brindarle las partidas jugadas no acertaba o su prediccion, lo que provocaba que su respuesta fuera inconsistente, dado que podia acertar en la posicion de las filas o columnas en este caso en 5 de cada 10 partidas. A continuacion puedes analizar una de sus respuestas

```md
**1. Filas libres probables:**

* **Fila 2** — 88.57% de vacíos históricos (tendencia creciente, pendiente +0.014)
* **Fila 5** — 88.57% de vacíos históricos (tendencia estable, pendiente +0.000)

**2. Columnas libres probables:**

* **Columna 5** — 85.71% de vacíos históricos (tendencia creciente, pendiente +0.057)
* **Columna 2** — 85.71% de vacíos históricos (tendencia decreciente, pendiente –0.050)

**3. Sugerencia de selección y punto de partida:**

*Fila a seleccionar:* Fila 2, por su tendencia creciente (pendiente +0.014) y libre en 3/7 partidas.

*Dónde empezar:*
En la casilla (columna 2, fila 2), que no ha registrado mina en las últimas 7 partidas.
Continuar hacia columnas 4 y 1, y evitar columna 3 (2 minas históricas).

*Fila a evitar:*
Fila 4, por tener solo 77.14% de vacíos históricos y tendencia decreciente (pendiente –0.057), libre en solo 2/7 partidas.

*Columna a seleccionar:* Columna 5, con tendencia creciente (pendiente +0.057) y limpia en 4/7 partidas.

*Dónde empezar:*
En la casilla (columna 5, fila 4), que nunca ha registrado mina en las últimas 7 partidas.
Avanzar hacia filas 2 y 3, y dejar para el final filas 1 y 5 (2 y 1 minas históricas, respectivamente).

*Columna a evitar:*
Columna 4, con solo 80.00% de vacíos históricos y tendencia decreciente (pendiente –0.014).

**4. ¿Por dónde empezar?**
Recomiendo comenzar por **la fila 2**, dado su mayor probabilidad de vacíos (88.57%) y pendiente positiva más pronunciada, frente a la columna 5 (85.71%).

**5. Zona de mayor riesgo (celdas a evitar):**

* **Cuadrante superior derecho** — 21.43% de concentración histórica
* **Celdas específicas de alto riesgo:** (5,1), (3,2), (4,1)

**6. Mapa de calor del tablero (5×5):**

```
   1  2  3  4  5
1 [2][2][0][1][2]
2 [1][0][2][0][1]
3 [0][1][0][3][1]
4 [2][2][2][2][0]
5 [1][0][1][1][1]
```

*Donde N = número de minas históricas en esa celda*

```

y lo puedes comparar con el resultado de la partida jugada
```csv
partida,columna,fila,mina
1,1,1,1
1,1,2,0
1,1,3,0
1,1,4,0
1,1,5,0
1,2,1,0
1,2,2,0
1,2,3,0
1,2,4,0
1,2,5,0
1,3,1,0
1,3,2,0
1,3,3,0
1,3,4,1
1,3,5,0
1,4,1,0
1,4,2,0
1,4,3,0
1,4,4,0
1,4,5,0
1,5,1,1
1,5,2,0
1,5,3,0
1,5,4,0
1,5,5,1
2,1,1,1
2,1,2,0
2,1,3,0
2,1,4,0
2,1,5,0
2,2,1,0
2,2,2,0
2,2,3,0
2,2,4,0
2,2,5,0
2,3,1,0
2,3,2,0
2,3,3,0
2,3,4,0
2,3,5,0
2,4,1,0
2,4,2,0
2,4,3,1
2,4,4,0
2,4,5,0
2,5,1,1
2,5,2,1
2,5,3,0
2,5,4,0
2,5,5,0
3,1,1,0
3,1,2,0
3,1,3,0
3,1,4,0
3,1,5,1
3,2,1,1
3,2,2,0
3,2,3,0
3,2,4,0
3,2,5,0
3,3,1,0
3,3,2,1
3,3,3,0
3,3,4,0
3,3,5,0
3,4,1,0
3,4,2,0
3,4,3,1
3,4,4,0
3,4,5,0
3,5,1,0
3,5,2,0
3,5,3,0
3,5,4,0
3,5,5,0
4,1,1,0
4,1,2,1
4,1,3,0
4,1,4,0
4,1,5,0
4,2,1,0
4,2,2,0
4,2,3,0
4,2,4,1
4,2,5,0
4,3,1,0
4,3,2,0
4,3,3,0
4,3,4,0
4,3,5,0
4,4,1,1
4,4,2,0
4,4,3,0
4,4,4,1
4,4,5,0
4,5,1,0
4,5,2,0
4,5,3,0
4,5,4,0
4,5,5,0
5,1,1,0
5,1,2,0
5,1,3,0
5,1,4,1
5,1,5,0
5,2,1,0
5,2,2,0
5,2,3,0
5,2,4,0
5,2,5,0
5,3,1,0
5,3,2,1
5,3,3,0
5,3,4,0
5,3,5,0
5,4,1,0
5,4,2,0
5,4,3,1
5,4,4,0
5,4,5,1
5,5,1,0
5,5,2,0
5,5,3,0
5,5,4,0
5,5,5,0
6,1,1,0
6,1,2,0
6,1,3,0
6,1,4,1
6,1,5,0
6,2,1,1
6,2,2,0
6,2,3,0
6,2,4,0
6,2,5,0
6,3,1,0
6,3,2,0
6,3,3,0
6,3,4,1
6,3,5,0
6,4,1,0
6,4,2,0
6,4,3,0
6,4,4,0
6,4,5,0
6,5,1,0
6,5,2,0
6,5,3,1
6,5,4,0
6,5,5,0
7,1,1,0
7,1,2,0
7,1,3,0
7,1,4,0
7,1,5,0
7,2,1,0
7,2,2,0
7,2,3,1
7,2,4,1
7,2,5,0
7,3,1,0
7,3,2,0
7,3,3,0
7,3,4,0
7,3,5,1
7,4,1,0
7,4,2,0
7,4,3,0
7,4,4,1
7,4,5,0
7,5,1,0
7,5,2,0
7,5,3,0
7,5,4,0
7,5,5,0
8,1,1,0
8,1,2,0
8,1,3,0
8,1,4,0
8,1,5,0
8,2,1,0
8,2,2,0
8,2,3,1
8,2,4,0
8,2,5,0
8,3,1,0
8,3,2,1
8,3,3,0
8,3,4,0
8,3,5,1
8,4,1,0
8,4,2,0
8,4,3,0
8,4,4,0
8,4,5,0
8,5,1,0
8,5,2,0
8,5,3,0
8,5,4,1
8,5,5,0
```

como puedes ver su prediccion es inconsistente a pesar de razonar

Entonces basado en lo anterior construye el prompt lo mas claro y sofisticado posible para que el agente de IA pueda entender el proposito del trnasformer el cual es predecir la ubicacion 3 minas en un tablero de 5x5, tomando el historico de los datos de las partidas jugadas como datos de entrenamiento para que de esta manera se definan las epocas y demas parametros necesarios para construir el transformer. Recuerda asignar un rol al agente de IA para que pueda entenderlo mejor y de esa manera construir el transformer o modelo de IA
